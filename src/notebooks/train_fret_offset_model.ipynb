{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "857ad30cbc9eac2e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from src.datasets import FretOffsetTrainDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from src.model import NotationModel, ModelConfig\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from pathlib import Path\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hyperparameters",
   "id": "9801ec72a33744a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "FEATURE_NUM = 2**9\n",
    "IN_CHANNELS = 2**6\n",
    "NUM_HEADS = 1\n",
    "IM_RES = 64\n",
    "AVG_POOL_DIM = 4\n",
    "EPOCH_NUM = 30\n",
    "LR = 1e-4\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 13"
   ],
   "id": "ebed029511588dff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "8cc030955d6f2768"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IM_RES, IM_RES), interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "augmentations = transforms.Compose([\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.04, 0.04))\n",
    "])"
   ],
   "id": "4af37d45ca653d78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.util import split_dataset\n",
    "\n",
    "basepath = Path().resolve().parent.parent\n",
    "labeled_tabs_path = basepath / \"data\" / \"labelled_fret_offsets.csv\"\n",
    "image_path = basepath / \"data\" / \"dataset\" / \"frets\"\n",
    "\n",
    "dataset = FretOffsetTrainDataset(labeled_tabs_path, image_path, transform, augmentations=augmentations)\n",
    "train_set, val_set = split_dataset(dataset, train_ratio=0.9)\n",
    "\n",
    "kwargs = {\n",
    "    \"num_workers\": NUM_WORKERS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"pin_memory\": True,\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, **kwargs)\n",
    "val_loader = DataLoader(val_set, shuffle=False, **kwargs)"
   ],
   "id": "bb61d22069cf3640",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.util import montage_from_ds\n",
    "\n",
    "# TODO: fix iteration\n",
    "montage_from_ds(train_set, 3)\n",
    "print(f\"Image shape: {train_set[0][0].shape}\")"
   ],
   "id": "dbbc62a21778fb7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Trainer Setup",
   "id": "3c73adcee4f77a73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    dirpath=\"model_checkpoints\",\n",
    "    filename=\"model-{epoch:02d}-{val_loss:.2f}\"\n",
    ")\n",
    "\n",
    "trainer_config = {\n",
    "    \"log_every_n_steps\": 3,\n",
    "    \"enable_model_summary\": True,\n",
    "    \"accelerator\": \"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    # \"profiler\": \"simple\",\n",
    "    \"enable_checkpointing\": False, \n",
    "    # \"callbacks\": [checkpoint_callback],\n",
    "    \"logger\": False\n",
    "}\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=EPOCH_NUM, **trainer_config)"
   ],
   "id": "ee47a601f794a4bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tab Prediction",
   "id": "bb062008a66e91f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_config = ModelConfig(num_classes=NUM_CLASSES,\n",
    "                           feature_num=FEATURE_NUM,\n",
    "                           im_res=IM_RES,\n",
    "                           num_heads=NUM_HEADS,\n",
    "                           in_channels=IN_CHANNELS,\n",
    "                           avg_pool_dim=AVG_POOL_DIM,\n",
    "                           learning_rate=LR)\n",
    "model = NotationModel(model_config)"
   ],
   "id": "686700f966a4594b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.fit(model, train_loader, val_loader)",
   "id": "ec12fbe5b526bd77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.util import show_loss_info\n",
    "\n",
    "tab_train_losses = model.train_losses\n",
    "tab_val_losses = model.val_losses[1:] # PyTorch Lightning performs 1 validation step before training starts\n",
    "show_loss_info(tab_train_losses, tab_val_losses)"
   ],
   "id": "b748fc4227b55c1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.datasets import TestDataset\n",
    "from src.util import model_montage, montage\n",
    "import random \n",
    "import os\n",
    "\n",
    "SHOW_NUM = 20\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "filenames = random.choices(os.listdir(image_path), k=SHOW_NUM)\n",
    "small_predict_dataset = TestDataset.from_dir(image_path, filenames=filenames, transform=transform)\n",
    "small_predict_loader = DataLoader(small_predict_dataset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    \n",
    "model_montage(small_predict_loader, model, show_num=SHOW_NUM)"
   ],
   "id": "45963182f29cc9d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "val_set.remove_augmentations()\n",
    "# TODO: Add Test set that has never been seen by the model and doesnt contain augmentations, also for validation set!!\n",
    "predict_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "misclassified = []\n",
    "for index, data in enumerate(predict_loader):\n",
    "    im, label = data\n",
    "    im = im.to(device)\n",
    "    classified = model.predict(im)\n",
    "    if label.item() == classified.item():\n",
    "        continue\n",
    "    misclassified.append((im[0], classified))\n",
    "\n",
    "montage(misclassified, SHOW_NUM)\n",
    "\n",
    "# TODO: Write function that converts logits to probabilities while not introducing under- / overconfidence\n",
    "# TODO: Compare confidence of misclassifications to correct classifications\n",
    "# TODO: Add more metrics other than train / val loss"
   ],
   "id": "3eba7a606e483132",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
